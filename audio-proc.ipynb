{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12033511,"sourceType":"datasetVersion","datasetId":7571482}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import librosa as lb\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport soundfile as sf\nimport noisereduce as nr\nfrom scipy.stats import pearsonr\nfrom IPython.display import Audio\nimport pyloudnorm as pyln\nfrom pedalboard import Pedalboard, Compressor, Limiter, Gain","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Song","metadata":{}},{"cell_type":"code","source":"song, sample_rate = lb.load(\"/kaggle/input/untangle-songs/fake friend.mp3\", mono=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculate BPM","metadata":{}},{"cell_type":"code","source":"def calculate_bpm(audio_path):\n    \n    onset_env = lb.onset.onset_strength(y=y, sr=sr)\n    tempo, _ = lb.beat.beat_track(onset_envelope=onset_env, sr=sr)\n    return tempo[0]\n\nbpm = calculate_bpm(y)\nbpm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modify tempo of the song","metadata":{}},{"cell_type":"code","source":"def calc_speed(bpm, changed_bpm):\n    return changed_bpm/bpm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def change_speed_and_pitch(audio_path, speed_factor, output_path):\n\n    # Change speed (tempo) but keep pitch\n    y_fast = lb.effects.time_stretch(y, rate=speed_factor)\n\n    # Save the processed file\n    sf.write(output_path, y_fast, sr)\n    print(f\"Processed file saved at {output_path}\")\n\nchange_speed_and_pitch('./goat.mp3', calc_speed(bpm, 26), './moreslo_goat.mp3')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Detect Key ","metadata":{}},{"cell_type":"code","source":"krumhansl_major_profile_base = np.array([\n    6.35,  # C\n    2.23,  # C#\n    3.48,  # D\n    2.33,  # D#\n    4.38,  # E\n    4.09,  # F\n    2.52,  # F#\n    5.19,  # G\n    2.39,  # G#\n    3.66,  # A\n    2.29,  # A#\n    2.88   # B\n])\n\n# Profile for minor keys (based on C minor for easier rolling)\nkrumhansl_minor_profile_base = np.array([\n    6.33,  # C (tonic of C minor)\n    2.68,  # C#\n    3.52,  # D\n    5.38,  # Eb (minor third)\n    2.60,  # E\n    3.53,  # F\n    2.54,  # F#\n    4.75,  # G (dominant)\n    3.98,  # G#\n    2.69,  # A\n    3.34,  # A#\n    3.17   # B\n])\n\n# List of pitch classes (keys)\nPITCH_CLASSES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n\ndef generate_key_profiles():\n    \"\"\"\n    Generates the 24 Krumhansl-Schmuckler key profiles (12 major, 12 minor).\n    \"\"\"\n    key_profiles = {}\n    for i in range(12):\n        # Major keys\n        major_key_name = f\"{PITCH_CLASSES[i]} major\"\n        major_profile = np.roll(krumhansl_major_profile_base, i)\n        key_profiles[major_key_name] = major_profile / np.sum(major_profile) # Normalize\n\n        # Minor keys\n        minor_key_name = f\"{PITCH_CLASSES[i]} minor\"\n        minor_profile = np.roll(krumhansl_minor_profile_base, i)\n        key_profiles[minor_key_name] = minor_profile / np.sum(minor_profile) # Normalize\n    return key_profiles\n\n# Pre-generate the profiles when the script loads\nALL_KEY_PROFILES = generate_key_profiles()\n\ndef detect_key_krumhansl(audio_path):\n    try:\n        # 1. Load the audio file\n        y, sr = lb.load(audio_path)\n        if len(y) == 0:\n            print(\"Warning: Audio file is empty or could not be loaded properly.\")\n            return \"Unknown\", 0.0\n\n        # 2. Extract chroma features\n        chromagram = lb.feature.chroma_stft(y=y, sr=sr)\n\n        # 3. Aggregate chroma features over time\n        song_chroma_profile = np.sum(chromagram, axis=1)\n        \n        # Handle cases where the song is silent or has no chromatic content\n        if np.sum(song_chroma_profile) == 0:\n            print(\"Warning: No chromatic content found in the audio.\")\n            return \"Unknown (No chromatic content)\", 0.0\n            \n        song_chroma_profile_normalized = song_chroma_profile / np.sum(song_chroma_profile)\n\n\n        # 4. Compare with Krumhansl-Schmuckler profiles\n        best_key = None\n        max_correlation = -np.inf  # Initialize with a very small number\n\n        for key_name, key_profile in ALL_KEY_PROFILES.items():\n            correlation, _ = pearsonr(song_chroma_profile_normalized, key_profile)\n\n            if correlation > max_correlation:\n                max_correlation = correlation\n                best_key = key_name\n        \n        if best_key is None:\n             return \"Unknown (Correlation failed)\", 0.0\n\n        return best_key, float(max_correlation)\n\n    except Exception as e:\n        print(f\"Error during key detection: {e}\")\n        return \"Unknown (Error)\", 0.0\n\nif __name__ == \"__main__\":\n\n    audio_file_path = song\n\n    try:\n        print(f\"Testing with user-provided file: {audio_file_path}\")\n        detected_key, confidence = detect_key_krumhansl(audio_file_path)\n        print(f\"Detected key: {detected_key}, Confidence (Correlation): {confidence:.4f}\")\n    except FileNotFoundError:\n        print(f\"Audio file not found: {audio_file_path}. Skipping this test.\")\n    except Exception as e:\n        print(f\"Could not process {audio_file_path} due to: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Shift Key\nEach step is eqv to half a note","metadata":{}},{"cell_type":"code","source":"def pitch_shift(audio_path, n_steps, output_path):\n    # Load the audio file\n    y, sr = lb.load(audio_path)\n    \n    # Perform pitch shift\n    y_shifted = lb.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n    \n    # Save the processed file\n    sf.write(output_path, y_shifted, sr)\n\n# Example: pitch_shift('input.mp3', 2, 'output.mp3')  # Shifts up by 2 semitones","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Noise Reduction","metadata":{}},{"cell_type":"code","source":"noise_subtracted = nr.reduce_noise(y = song, sr = sample_rate)\ndisplay(Audio(data=noise_subtracted, rate=sample_rate))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loudness Determination & Normalisation.","metadata":{}},{"cell_type":"code","source":"TARGET_LUFS = -14.0\nTARGET_PEAK_DBFS = -1.0 # Target peak after any processing to avoid clipping\n\n# --- 1. Initial Loudness Analysis ---\nmeter = pyln.Meter(sample_rate)\nog_lufs = meter.integrated_loudness(song)\nog_lra = meter.loudness_range(song)\nog_dbfs = 20 * np.log10(np.max(np.abs(song)))\n\nprint(f\"\\n--- Initial Audio Stats ---\")\nprint(f\"Integrated Loudness: {og_lufs:.2f} LUFS\")\nprint(f\"Loudness Range (LRA): {og_lra:.2f} LU\")\nprint(f\"Peak: {og_dbfs:.2f} dBFS\")\n\nprocessed_song_arr = song.copy()\n\n# --- 2. Conditional Processing based on LRA ---\nif og_lra < 7.0 or og_lra > 16.0:\n    print(f\"\\n--- LRA ({og_lra:.2f} LU) is outside 7-16 LU range. Applying LUFS Normalization. ---\")\n    gain_db = TARGET_LUFS - og_lufs\n    gain_linear = 10 ** (gain_db / 20.0)\n    processed_song_arr = processed_song_arr * gain_linear\n    print(f\"Applied {gain_db:.2f} dB gain for LUFS normalization.\")\n\nelse:\n    print(f\"\\n--- LRA ({og_lra:.2f} LU) is within 7-16 LU range. Applying Dynamic Range Compression. ---\")\n\n    # Define compressor and limiter settings. Future-Scope: Modifiable via UI. Unlikely to be implemented.\n    board = Pedalboard([\n        Compressor(threshold_db=-20, ratio=4, attack_ms=5.0, release_ms=150.0),\n        Limiter(threshold_db=TARGET_PEAK_DBFS, release_ms=50.0) # Limiter to prevent peaks\n    ])\n\n    # Apply effects\n    # Pedalboard expects float32, librosa might return float64\n    processed_song_arr = board(processed_song_arr.astype(np.float32), sample_rate=sample_rate)\n    print(\"Applied Compressor and Limiter.\")\n\n    # After compression, the LUFS will have changed. Re-normalize to target LUFS.\n    compressed_lufs = meter.integrated_loudness(processed_song_arr)\n    gain_db_compressed = TARGET_LUFS - compressed_lufs\n    \n    # Apply gain using Pedalboard.Gain for consistency and to handle float32\n    gain_board = Pedalboard([Gain(gain_db=gain_db_compressed)])\n    processed_song_arr = gain_board(processed_song_arr.astype(np.float32), sample_rate = sample_rate)\n    print(f\"Applied {gain_db_compressed:.2f} dB gain to reach target LUFS post-compression.\")\n\n\n# --- 3. Final Peak Normalization/Limiting (Safety Net) ---\n# Ensure the final audio does not exceed TARGET_PEAK_DBFS\ncurrent_peak_linear = np.max(np.abs(processed_song_arr))\ntarget_peak_linear = 10 ** (TARGET_PEAK_DBFS / 20.0)\n\nif current_peak_linear > target_peak_linear and current_peak_linear > 0: # also check current_peak_linear > 0 to avoid div by zero if silent\n    print(f\"Final peak ({20*np.log10(current_peak_linear):.2f} dBFS) exceeds target. Applying peak normalization.\")\n    peak_norm_gain = target_peak_linear / current_peak_linear\n    processed_song_arr = processed_song_arr * peak_norm_gain\nelse:\n    print(\"Final peak is within target limits.\")\n\n# --- 4. Final Loudness Check & Output ---\nfinal_lufs = meter.integrated_loudness(processed_song_arr)\nfinal_lra = meter.loudness_range(processed_song_arr)\nfinal_peak_dbfs = 20 * np.log10(np.max(np.abs(processed_song_arr)))\n\nprint(f\"\\n--- Processed Audio Stats ---\")\nprint(f\"Final Integrated Loudness: {final_lufs:.2f} LUFS (Target: {TARGET_LUFS:.2f} LUFS)\")\nprint(f\"Final Loudness Range (LRA): {final_lra:.2f} LU\")\nprint(f\"Final Peak: {final_peak_dbfs:.2f} dBFS (Target: <= {TARGET_PEAK_DBFS:.2f} dBFS)\")\n\n\nprint(\"\\nOriginal Audio:\")\ndisplay(Audio(data=data, rate = sample_rate))\n\nprint(\"\\nProcessed Audio:\")\ndisplay(Audio(data=processed_song_arr, rate = sample_rate))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def change_speed_and_pitch(audio_data, sr, speed_factor):\n#     \"\"\"\n#     Changes the speed of audio data without saving to file\n#     Parameters:\n#         audio_data: numpy array of audio samples\n#         sr: sample rate\n#         speed_factor: factor to change speed (e.g., 1.2 for 20% faster)\n#     Returns:\n#         processed audio data as numpy array\n#     \"\"\"\n#     # Change speed (tempo) but keep pitch\n#     y_processed = lb.effects.time_stretch(audio_data, rate=speed_factor)\n    \n#     return y_processed, sr","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load audio once\n# y, sr = lb.load(\"input.mp3\")\n\n# # Process audio when speed change is requested (e.g., from a slider in UI)\n# def on_speed_change(speed_factor):\n#     processed_audio, sr = change_speed_and_pitch(y, sr, speed_factor)\n#     # Here you would send processed_audio to your audio playback system\n#     return processed_audio","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}